{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pair, t_start, t_stop, bin_size):\n",
    "    time_step = 60000000\n",
    "    limit = 1000\n",
    "    df = {}\n",
    "    path = f'./data/{pair}_{t_start}-{t_stop}_{bin_size}.csv'\n",
    "    if (os.path.exists(path)) and (os.path.isfile(path)):\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        data = fetch_data(start=t_start, stop=t_stop, symbol=pair, interval=bin_size, tick_limit=limit, step=time_step)\n",
    "        names = ['time', 'open', 'close', 'high', 'low', 'volume']\n",
    "        df = pd.DataFrame(data, columns=names)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "        df.set_index('time', inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "        print(df.head())\n",
    "        df.to_csv(f'./data/{pair}_{t_start}-{t_stop}_{bin_size}.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-31 23:00:00</th>\n",
       "      <td>9158.900000</td>\n",
       "      <td>9159.000000</td>\n",
       "      <td>9159.000000</td>\n",
       "      <td>9152.900000</td>\n",
       "      <td>0.216948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 23:01:00</th>\n",
       "      <td>9157.000000</td>\n",
       "      <td>9152.600000</td>\n",
       "      <td>9160.000000</td>\n",
       "      <td>9152.600000</td>\n",
       "      <td>0.160750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 23:02:00</th>\n",
       "      <td>9151.971187</td>\n",
       "      <td>9148.960156</td>\n",
       "      <td>9154.400000</td>\n",
       "      <td>9147.398881</td>\n",
       "      <td>0.295918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 23:03:00</th>\n",
       "      <td>9149.400000</td>\n",
       "      <td>9149.000000</td>\n",
       "      <td>9149.400000</td>\n",
       "      <td>9149.000000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 23:04:00</th>\n",
       "      <td>9151.371226</td>\n",
       "      <td>9151.342113</td>\n",
       "      <td>9151.378378</td>\n",
       "      <td>9151.342113</td>\n",
       "      <td>0.020960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open        close         high          low  \\\n",
       "time                                                                      \n",
       "2019-10-31 23:00:00  9158.900000  9159.000000  9159.000000  9152.900000   \n",
       "2019-10-31 23:01:00  9157.000000  9152.600000  9160.000000  9152.600000   \n",
       "2019-10-31 23:02:00  9151.971187  9148.960156  9154.400000  9147.398881   \n",
       "2019-10-31 23:03:00  9149.400000  9149.000000  9149.400000  9149.000000   \n",
       "2019-10-31 23:04:00  9151.371226  9151.342113  9151.378378  9151.342113   \n",
       "\n",
       "                       volume  \n",
       "time                           \n",
       "2019-10-31 23:00:00  0.216948  \n",
       "2019-10-31 23:01:00  0.160750  \n",
       "2019-10-31 23:02:00  0.295918  \n",
       "2019-10-31 23:03:00  0.020000  \n",
       "2019-10-31 23:04:00  0.020960  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = datetime.datetime(2019, 11, 1, 0, 0)\n",
    "t_start = time.mktime(t_start.timetuple()) * 1000\n",
    "\n",
    "t_stop = datetime.datetime(2019, 12, 1, 0, 0)\n",
    "t_stop = time.mktime(t_stop.timetuple()) * 1000\n",
    "\n",
    "df = get_data(pair='btcusd', t_start=t_start, t_stop=t_stop, bin_size='1m')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35006 8752\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "test_size = len(df) - train_size\n",
    "train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Husar\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Husar\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Husar\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Husar\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Husar\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Husar\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "f_columns = ['open', 'high', 'low', 'volume']\n",
    "\n",
    "f_transformer = RobustScaler()\n",
    "\n",
    "f_transformer = f_transformer.fit(train[f_columns].to_numpy())\n",
    "\n",
    "train.loc[:, f_columns] = f_transformer.transform(\n",
    "  train[f_columns].to_numpy()\n",
    ")\n",
    "\n",
    "test.loc[:, f_columns] = f_transformer.transform(\n",
    "  test[f_columns].to_numpy()\n",
    ")\n",
    "\n",
    "cnt_transformer = RobustScaler()\n",
    "\n",
    "cnt_transformer = cnt_transformer.fit(train[['close']])\n",
    "\n",
    "train['close'] = cnt_transformer.transform(train[['close']])\n",
    "\n",
    "test['close'] = cnt_transformer.transform(test[['close']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34996, 10, 5) (34996,)\n"
     ]
    }
   ],
   "source": [
    "time_steps = 10\n",
    "\n",
    "# reshape to [samples, time_steps, n_features]\n",
    "\n",
    "X_train, y_train = create_dataset(train, train.close, time_steps)\n",
    "X_test, y_test = create_dataset(test, test.close, time_steps)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(\n",
    "  keras.layers.Bidirectional(\n",
    "    keras.layers.LSTM(\n",
    "      units=128,\n",
    "      input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "    )\n",
    "  )\n",
    ")\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(units=1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27996 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "27996/27996 [==============================] - 15s 548us/sample - loss: 0.0116 - val_loss: 0.1633\n",
      "Epoch 2/10\n",
      "27996/27996 [==============================] - 8s 303us/sample - loss: 0.0044 - val_loss: 0.0764\n",
      "Epoch 3/10\n",
      "27996/27996 [==============================] - 10s 341us/sample - loss: 0.0031 - val_loss: 0.0392\n",
      "Epoch 4/10\n",
      "27996/27996 [==============================] - 17s 613us/sample - loss: 0.0022 - val_loss: 0.0245\n",
      "Epoch 5/10\n",
      "27996/27996 [==============================] - 13s 448us/sample - loss: 0.0016 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "27996/27996 [==============================] - 13s 459us/sample - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      " 6016/27996 [=====>........................] - ETA: 8s - loss: 0.0019"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_train_inv = cnt_transformer.inverse_transform(y_train.reshape(1, -1))\n",
    "y_test_inv = cnt_transformer.inverse_transform(y_test.reshape(1, -1))\n",
    "y_pred_inv = cnt_transformer.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(y_train)), y_train_inv.flatten(), 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test_inv.flatten(), marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred_inv.flatten(), 'r', label=\"prediction\")\n",
    "plt.ylabel('close')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_inv.flatten(), marker='.', label=\"true\")\n",
    "plt.plot(y_pred_inv.flatten(), 'r', label=\"prediction\")\n",
    "plt.ylabel('Bike Count')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
